{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import Integer, Date, Time,Text\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from prefect import flow, task\n",
    "from prefect.tasks import task_input_hash\n",
    "from prefect_sqlalchemy import SqlAlchemyConnector\n",
    "\n",
    "import pprint\n",
    "from metabase import Metabase\n",
    "from metabase_api import Metabase_API\n",
    "\n",
    "import pipeline_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://data.cityofnewyork.us/api/views/h9gi-nx95/rows.csv?accessType=DOWNLOAD'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_set.url_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://data.cityofnewyork.us/api/views/h9gi-nx95/rows.csv?accessType=DOWNLOAD'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(pipeline_set, \"url_C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(data_type):\n",
    "    if data_type == \"check\":\n",
    "        return(\"check\", data_type)\n",
    "    elif data_type == \"metabase\":\n",
    "        return(\"metabase\", data_type)\n",
    "    elif data_type[:1] in [\"C\",\"V\",\"P\"] and data_type[1:] == \" reload\":\n",
    "        data_type = data_type[:1]\n",
    "        url = getattr(pipeline_set,f\"url_{data_type}\")\n",
    "        csv_name = f\"MVC_{data_type}.csv\"\n",
    "        os.system(f\"wget {url} -O {csv_name}\")\n",
    "        return(csv_name, data_type)\n",
    "    elif data_type in [\"C\",\"V\",\"P\"]:\n",
    "        url = getattr(pipeline_set,f\"url_{data_type}\")\n",
    "        csv_name = f\"MVC_{data_type}.csv\"\n",
    "        if os.path.isfile(csv_name) is not True:\n",
    "            os.system(f\"wget {url} -O {csv_name}\")\n",
    "            return(csv_name, data_type)\n",
    "        else:\n",
    "            return(csv_name, data_type)\n",
    "    else:\n",
    "        return(\"err\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(csv_name:str, years:list , data_type:str):\n",
    "    # Reads the csv\n",
    "    df = pd.read_csv(csv_name, nrows = 1000, low_memory=False)\n",
    "    # Selects specified columns\n",
    "    df = df[getattr(pipeline_set,f\"sel_{data_type}\")]\n",
    "    # Rename them \n",
    "    df.rename(columns=(getattr(pipeline_set,f\"sel_rename_{data_type}\")),inplace=True)\n",
    "    # Convert to datetime type in datetime columns\n",
    "    df.crash_date = pd.to_datetime(df.crash_date).dt.date\n",
    "    df.crash_time = pd.to_datetime(df.crash_time,format= '%H:%M' ).dt.time\n",
    "\n",
    "    # Creates empty tables in a database\n",
    "    engine = create_engine('postgresql://root:root@localhost:5432/MVC_db') \n",
    "    \n",
    "    for i in years:\n",
    "        df.head(n=0).to_sql(name = f\"MVC_{data_type}_{i}\",con = engine, dtype=(getattr(pipeline_set,f\"sel_types_{data_type}\")),if_exists = 'replace')\n",
    "\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql://root:***@localhost:5432/MVC_db)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_name = 'MVC_C.csv'\n",
    "years = [i for i in range(2017,2024)]\n",
    "data_type = 'C'\n",
    "\n",
    "create_tables(csv_name, years, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_and_load(years:list, csv_name:str, engine, data_type:str):\n",
    "    \n",
    "    total_rows=0\n",
    "    total_rows_loaded = 0\n",
    "    total_time = 0\n",
    "\n",
    "    # Iterates through chunks of data from the CSV\n",
    "    df_iter = pd.read_csv(csv_name, iterator = True, chunksize = 100000, low_memory=False)\n",
    "    df = next(df_iter)\n",
    "    \n",
    "    while len(df) > 0:\n",
    "        try:\n",
    "            start_time = time()\n",
    "            \n",
    "            # Process data\n",
    "            df = df[getattr(pipeline_set,f\"sel_{data_type}\")]\n",
    "            df.rename(columns=(getattr(pipeline_set,f\"sel_rename_{data_type}\")),inplace=True)\n",
    "            df.crash_date = pd.to_datetime(df.crash_date).dt.date\n",
    "            df.crash_time = pd.to_datetime(df.crash_time,format= '%H:%M' ).dt.time\n",
    "            \n",
    "            total_rows += len(df)\n",
    "            \n",
    "            # Appends them to the tables\n",
    "            for i in years:\n",
    "                df_temp = df.loc[pd.DatetimeIndex(df.crash_date).year == i]\n",
    "                df_temp.to_sql(name = f\"MVC_{data_type}_{i}\",con = engine, if_exists = 'append')\n",
    "                \n",
    "                total_rows_loaded += len(df_temp)\n",
    "            \n",
    "\n",
    "            end_time = time()\n",
    "            total_time += (end_time - start_time)\n",
    "\n",
    "\n",
    "            print(\n",
    "            f\"total rows processed = {total_rows}\", \n",
    "            f\"total rows loaded = {total_rows_loaded}\", \n",
    "            'iteration took %.2f seconds' % (end_time - start_time),\n",
    "            f\"total time = %.2f seconds\" % (total_time),\n",
    "            \"\", sep = \"\\n\")\n",
    "\n",
    "            df = next(df_iter)\n",
    "\n",
    "        except StopIteration:\n",
    "            print(\"Finished ingesting data into the postgres database\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows processed = 100000\n",
      "total rows loaded = 100000\n",
      "iteration took 6.44 seconds\n",
      "total time = 6.44 seconds\n",
      "\n",
      "total rows processed = 200000\n",
      "total rows loaded = 200000\n",
      "iteration took 6.33 seconds\n",
      "total time = 12.77 seconds\n",
      "\n",
      "total rows processed = 300000\n",
      "total rows loaded = 300000\n",
      "iteration took 6.24 seconds\n",
      "total time = 19.01 seconds\n",
      "\n",
      "total rows processed = 400000\n",
      "total rows loaded = 400000\n",
      "iteration took 6.01 seconds\n",
      "total time = 25.02 seconds\n",
      "\n",
      "total rows processed = 500000\n",
      "total rows loaded = 500000\n",
      "iteration took 5.86 seconds\n",
      "total time = 30.88 seconds\n",
      "\n",
      "total rows processed = 600000\n",
      "total rows loaded = 600000\n",
      "iteration took 6.34 seconds\n",
      "total time = 37.22 seconds\n",
      "\n",
      "total rows processed = 700000\n",
      "total rows loaded = 700000\n",
      "iteration took 5.94 seconds\n",
      "total time = 43.16 seconds\n",
      "\n",
      "total rows processed = 800000\n",
      "total rows loaded = 800000\n",
      "iteration took 6.15 seconds\n",
      "total time = 49.31 seconds\n",
      "\n",
      "total rows processed = 900000\n",
      "total rows loaded = 900000\n",
      "iteration took 6.21 seconds\n",
      "total time = 55.52 seconds\n",
      "\n",
      "total rows processed = 1000000\n",
      "total rows loaded = 1000000\n",
      "iteration took 6.04 seconds\n",
      "total time = 61.56 seconds\n",
      "\n",
      "total rows processed = 1100000\n",
      "total rows loaded = 1100000\n",
      "iteration took 6.21 seconds\n",
      "total time = 67.77 seconds\n",
      "\n",
      "total rows processed = 1200000\n",
      "total rows loaded = 1200000\n",
      "iteration took 6.05 seconds\n",
      "total time = 73.82 seconds\n",
      "\n",
      "total rows processed = 1300000\n",
      "total rows loaded = 1300000\n",
      "iteration took 6.24 seconds\n",
      "total time = 80.06 seconds\n",
      "\n",
      "total rows processed = 1400000\n",
      "total rows loaded = 1400000\n",
      "iteration took 6.16 seconds\n",
      "total time = 86.22 seconds\n",
      "\n",
      "total rows processed = 1500000\n",
      "total rows loaded = 1500000\n",
      "iteration took 6.27 seconds\n",
      "total time = 92.50 seconds\n",
      "\n",
      "total rows processed = 1600000\n",
      "total rows loaded = 1600000\n",
      "iteration took 6.18 seconds\n",
      "total time = 98.68 seconds\n",
      "\n",
      "total rows processed = 1700000\n",
      "total rows loaded = 1700000\n",
      "iteration took 6.30 seconds\n",
      "total time = 104.97 seconds\n",
      "\n",
      "total rows processed = 1800000\n",
      "total rows loaded = 1800000\n",
      "iteration took 6.30 seconds\n",
      "total time = 111.28 seconds\n",
      "\n",
      "total rows processed = 1900000\n",
      "total rows loaded = 1900000\n",
      "iteration took 6.03 seconds\n",
      "total time = 117.31 seconds\n",
      "\n",
      "total rows processed = 2000000\n",
      "total rows loaded = 2000000\n",
      "iteration took 5.74 seconds\n",
      "total time = 123.05 seconds\n",
      "\n",
      "total rows processed = 2031372\n",
      "total rows loaded = 2031372\n",
      "iteration took 2.01 seconds\n",
      "total time = 125.06 seconds\n",
      "\n",
      "Finished ingesting data into the postgres database\n"
     ]
    }
   ],
   "source": [
    "csv_name = 'MVC_C.csv'\n",
    "years = [i for i in range(2012,2024)]\n",
    "data_type = 'C'\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/MVC_db')\n",
    "\n",
    "transform_and_load(years, csv_name, engine, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_downloaded_data():\n",
    "    engine = create_engine('postgresql://root:root@localhost:5432/MVC_db')\n",
    "\n",
    "    res = [['year', 'Crashes','Vehicles','Person']]\n",
    "    \n",
    "    # Verifies data presence in the database and prints out summaries.\n",
    "    for i in range(2012,2024):\n",
    "        print(f\"{i} spreadsheets check\")\n",
    "        temp = []\n",
    "        temp.append(i)\n",
    "        try:\n",
    "            df = pd.read_sql_query('(SELECT COUNT(*) FROM \"MVC_C_{}\" )'.format(i),con=engine)\n",
    "            t = int(df.get(key = 'count'))\n",
    "        except:\n",
    "            t = 0\n",
    "        temp.append(t)\n",
    "        try:\n",
    "            df = pd.read_sql_query('(SELECT COUNT(*) FROM \"MVC_V_{}\" )'.format(i),con=engine)\n",
    "            t = int(df.get(key = 'count'))\n",
    "        except:\n",
    "            t = 0\n",
    "        temp.append(t)\n",
    "        try:\n",
    "            df = pd.read_sql_query('(SELECT COUNT(*) FROM \"MVC_P_{}\" )'.format(i),con=engine)\n",
    "            t = int(df.get(key = 'count'))\n",
    "        except:\n",
    "            t = 0\n",
    "        temp.append(t)\n",
    "        res.append(temp)\n",
    "    C,V,P =0,0,0\n",
    "    st = '   Downloaded data report:' + '\\n'  + '\\n'\n",
    "    for i in range(13):\n",
    "        for j in range(4):\n",
    "            if i == 0 or j == 0:\n",
    "                h = res[i][j]\n",
    "            else: \n",
    "                h = \"{:,}\".format(res[i][j])\n",
    "            st += str(h).rjust(11)\n",
    "        st += '\\n'\n",
    "        if i > 0:\n",
    "            C += int(res[i][1])\n",
    "            V += int(res[i][2])\n",
    "            P += int(res[i][3])\n",
    "    st = st + '\\n' + 'total'.rjust(11) + str(\"{:,}\".format(C)).rjust(11) + str(\"{:,}\".format(V)).rjust(11) + str(\"{:,}\".format(P)).rjust(11)\n",
    "    print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Crashes'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [['year', 'Crashes','Vehicles','Person']]\n",
    "res[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012 spreadsheets check\n",
      "2013 spreadsheets check\n",
      "2014 spreadsheets check\n",
      "2015 spreadsheets check\n",
      "2016 spreadsheets check\n",
      "2017 spreadsheets check\n",
      "2018 spreadsheets check\n",
      "2019 spreadsheets check\n",
      "2020 spreadsheets check\n",
      "2021 spreadsheets check\n",
      "2022 spreadsheets check\n",
      "2023 spreadsheets check\n",
      "   Downloaded data report:\n",
      "\n",
      "       year    Crashes   Vehicles     Person\n",
      "       2012    100,545          0          0\n",
      "       2013    203,740          0          0\n",
      "       2014    206,033          0          0\n",
      "       2015    217,694          0          0\n",
      "       2016    229,831          0          0\n",
      "       2017    231,007          0          0\n",
      "       2018    231,564          0          0\n",
      "       2019    211,486          0          0\n",
      "       2020    112,916          0          0\n",
      "       2021    110,548          0          0\n",
      "       2022    103,875          0          0\n",
      "       2023     72,133          0          0\n",
      "\n",
      "      total  2,031,372          0          0\n"
     ]
    }
   ],
   "source": [
    "check_downloaded_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metabase(years:list):\n",
    "    # Connection creation\n",
    "    mblogin = 'root@gmail.com'\n",
    "    mbpass = 'Aa123456@'\n",
    "    try:\n",
    "        mb = Metabase_API('http://localhost:3001/', mblogin, mbpass)\n",
    "        print(\"connection ok\")\n",
    "    except:\n",
    "        print(\"connection failed\")\n",
    "    \n",
    "    try:\n",
    "        colid = mb.get_item_id('collection', \"MVC_collection\")\n",
    "        print(\"collection 'MVC_collection' exists\")\n",
    "        print(f'colid: {colid}')\n",
    "    except:\n",
    "        print('no collection')\n",
    "    \n",
    "    try:\n",
    "        dbid = mb.get_item_id('database', \"MVC_collection\")\n",
    "        print(\"database ok\")\n",
    "        print(f'dbid: {dbid}')\n",
    "    except:\n",
    "        print(\"MVC_db not found:connect or rename database\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection ok\n",
      "collection 'MVC_collection' exists\n",
      "colid: 3\n",
      "database ok\n",
      "dbid: 2\n"
     ]
    }
   ],
   "source": [
    "years = [i for i in range(2012,2024)]\n",
    "metabase(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection 'MVC_collection' exists\n"
     ]
    }
   ],
   "source": [
    "mblogin = 'root@gmail.com'\n",
    "mbpass = 'Aa123456@'\n",
    "mb = Metabase_API('http://localhost:3001/', mblogin, mbpass)\n",
    "colid = mb.get_item_id('collection', \"MVC\")\n",
    "print(\"collection 'MVC_collection' exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_id = mb.get_item_id('collection', \"MVC_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "BASE_URL = \"http://localhost:3001/\"\n",
    "login_payload = {\n",
    "    \"username\": \"root@gmail.com\",\n",
    "    \"password\": \"Aa123456@\"\n",
    "}\n",
    "\n",
    "response = requests.post(BASE_URL + \"api/session\", json=login_payload)\n",
    "assert response.status_code == 200, \"Failed to log in\"\n",
    "\n",
    "token = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"X-Metabase-Session\": token\n",
    "}\n",
    "\n",
    "response = requests.get(BASE_URL + \"api/collection\", headers=headers)\n",
    "collections = response.json()\n",
    "\n",
    "collection_id = None\n",
    "for collection in collections:\n",
    "    if collection['name'] == \"MVC_collection\":\n",
    "        collection_id = collection['id']\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(BASE_URL + f\"api/collection/{collection_id}/items\", headers=headers)\n",
    "cards_in_collection = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['total', 'data', 'models', 'limit', 'offset'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards_in_collection.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cards_in_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_card = None\n",
    "for card in cards_in_collection['data']:\n",
    "    if card['model'] == 'card' and card['name'] == 'Activity, Count':\n",
    "        target_card = card\n",
    "        break\n",
    "\n",
    "if target_card:\n",
    "    with open('output.json', 'w') as f:\n",
    "        json.dump(target_card, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dash = {\n",
    "    \"description\": null,\n",
    "    \"collection_position\": null,\n",
    "    \"database_id\": null,\n",
    "    \"name\": \"Activity, Count\",\n",
    "    \"moderated_status\": null,\n",
    "    \"fully_parametrized\": true,\n",
    "    \"id\": 1,\n",
    "    \"display\": \"scalar\",\n",
    "    \"entity_id\": \"tk8rsT7qYHhGI3YWqLfu6\",\n",
    "    \"collection_preview\": true,\n",
    "    \"last-edit-info\": {\n",
    "        \"id\": 1,\n",
    "        \"last_name\": null,\n",
    "        \"first_name\": \"root\",\n",
    "        \"email\": \"root@gmail.com\",\n",
    "        \"timestamp\": \"2023-10-08T17:00:04.89381Z\"\n",
    "    },\n",
    "    \"model\": \"card\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
